{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microsoft ML MNIST Deep Learning Tutorial\n",
    "\n",
    "1. [Overview](#Overview)\n",
    "2. [Fitting Models That Identify Handprint Digits](#Digits)\n",
    "3. [What's Next?](#Next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"Overview\">1. OVERVIEW</a>\n",
    "\n",
    "Microsoft Machine Learning, or Microsoft ML for short, is an R package within Microsoft R Services that includes powerful machine learning algorithms and associated tools. The tutorial is an introduction to Microsoft ML for data scientists who want to take advantage of its unique capabilities.  It is intended primarily for those who are comfortable with using Microsoft R Services for data science, and want to see an end-to-end example that uses Microsoft ML to carry out common data science tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"Digits\">2. FITTING MODELS THAT IDENTIFY HANDPRINT DIGITS</a>\n",
    "\n",
    "The tutorial steps through the fitting of a model for identifying handprinted digits from 0 through 9 in carefully prepared gray-scale images. Since there are ten digits to identify, this is called a multi-class classification problem.\n",
    "\n",
    "The tutorial begins from data imported from a database of MNIST images. In this tutorial, the features are the pixel values of the images. Then, a model is fit by multiple learning algorithms, and the performance of these fit models is compared to select the best one. The initial and final steps in this process will be familiar to Microsoft R Services users, while the model fitting and performance evaluation steps will involve new Microsoft ML commands.\n",
    "\n",
    "This tutorial is an example of deep learning because it shows the use of convolutional neural networks to automatically learn features from images, before using these features to classify the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <a id=\"Packages\">2.1. LOADING THE PACKAGES</a>\n",
    "\n",
    "The tutorial is broken into steps, the first being loading the Microsoft ML package. When you execute the first step, there should be no output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------\n",
    "# 1. Load packages.\n",
    "#-----------------------------------------------------------------------\n",
    "if (!suppressPackageStartupMessages(require(\"MicrosoftML\",\n",
    "                                            quietly = TRUE,\n",
    "                                            warn.conflicts = FALSE))) {\n",
    "    stop(\"The MicrosoftML package does not seem to be installed, so this\\n\",\n",
    "         \"script cannot be run. If Microsoft R Server with MML is installed,\\n\",\n",
    "         \"you may need to switch the R engine option. In R Tools for Visual\\n\",\n",
    "         \"Studio, this option is under:\\n\",\n",
    "         \"\\tR Tools -> Options -> R Engine.\\n\",\n",
    "         \"If Microsoft R Server with MML is not installed, you can download it\\n\",\n",
    "         \"from https://microsoft.sharepoint.com/teams/TLC/SitePages/MicrosoftML.aspx\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Import\">2.2. IMPORT DATA</a>\n",
    "\n",
    "The second step consists of importing the data we will use to fit a model. There is only one table of data: the MNIST table. This section imports that table into an Xdf. These Xdfs are an efficient way of working with large amounts of data. They are files in which the rows are grouped in blocks whose size is specified by the parameter rowsPerBlock (omitted here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------\n",
    "# 2. Import data.\n",
    "#-----------------------------------------------------------------------\n",
    "\n",
    "# The directory containing data files.\n",
    "dataDir <- file.path(\"Data\")\n",
    "\n",
    "# Verify that the data file exists.\n",
    "if (!file.exists(file.path(dataDir, \"MNIST.xdf\"))) {\n",
    "    stop(\"The data files needed for running this script cannot be found.\\n\",\n",
    "         \"You may need to set R's working directory to the location of the Data\\n\",\n",
    "         \"directory.\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST table has one row per image, and 786 columns: Label, V2 through V785, and splitVar. The Label identifies the digit present in the image, one of 0, 1, 2, 3, 4, 5, 6, 7, 8, or 9. The V2 through V785 are the pixels of the 28 by 28 pixel images. And the splitVar identifies which images have historically been used in training and which have been used in testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The imported MNIST images.\n",
    "dataset <- RxXdfData(file.path(dataDir, \"MNIST.xdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the output that the activity table has 70,000 rows. Counts showing the number of images for each digit can be obtained as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows Read: 10000, Total Rows Processed: 10000, Total Chunk Time: 0.005 seconds\n",
      "Rows Read: 10000, Total Rows Processed: 20000, Total Chunk Time: 0.001 seconds\n",
      "Rows Read: 10000, Total Rows Processed: 30000, Total Chunk Time: Less than .001 seconds\n",
      "Rows Read: 10000, Total Rows Processed: 40000, Total Chunk Time: Less than .001 seconds\n",
      "Rows Read: 10000, Total Rows Processed: 50000, Total Chunk Time: Less than .001 seconds\n",
      "Rows Read: 10000, Total Rows Processed: 60000, Total Chunk Time: Less than .001 seconds\n",
      "Rows Read: 10000, Total Rows Processed: 70000, Total Chunk Time: 0.001 seconds \n",
      "Computation time: 0.022 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Label</th><td>0   </td><td>1   </td><td>2   </td><td>3   </td><td>4   </td><td>5   </td><td>6   </td><td>7   </td><td>8   </td><td>9   </td></tr>\n",
       "\t<tr><th scope=row>Counts</th><td>6903</td><td>7877</td><td>6990</td><td>7141</td><td>6824</td><td>6313</td><td>6876</td><td>7293</td><td>6825</td><td>6958</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       "\tLabel & 0    & 1    & 2    & 3    & 4    & 5    & 6    & 7    & 8    & 9   \\\\\n",
       "\tCounts & 6903 & 7877 & 6990 & 7141 & 6824 & 6313 & 6876 & 7293 & 6825 & 6958\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "1. '0'\n",
       "2. '6903'\n",
       "3. '1'\n",
       "4. '7877'\n",
       "5. '2'\n",
       "6. '6990'\n",
       "7. '3'\n",
       "8. '7141'\n",
       "9. '4'\n",
       "10. '6824'\n",
       "11. '5'\n",
       "12. '6313'\n",
       "13. '6'\n",
       "14. '6876'\n",
       "15. '7'\n",
       "16. '7293'\n",
       "17. '8'\n",
       "18. '6825'\n",
       "19. '9'\n",
       "20. '6958'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n",
       "Label  0    1    2    3    4    5    6    7    8    9    \n",
       "Counts 6903 7877 6990 7141 6824 6313 6876 7293 6825 6958 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t(as.data.frame(rxSummary(~ Label, dataset)$categorical))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Split\">2.3. SPLIT THE DATASET INTO TRAIN AND TEST</a>\n",
    "\n",
    "To create train and test sets, data are usually randomly split by tweet into two datasets. For this tutorial, we will use the split historically used for these data by Yann LeCun, as is given by the column splitVar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows Read: 10000, Total Rows Processed: 10000, Total Chunk Time: 0.218 seconds \n",
      "Rows Read: 10000, Total Rows Processed: 10000, Total Chunk Time: 1.292 secondsRows Read: 10000, Total Rows Processed: 10000, Total Chunk Time: 0.223 seconds \n",
      "Rows Read: 10000, Total Rows Processed: 20000, Total Chunk Time: 0.983 secondsRows Read: 10000, Total Rows Processed: 10000, Total Chunk Time: 0.246 seconds \n",
      "Rows Read: 10000, Total Rows Processed: 30000, Total Chunk Time: 0.997 secondsRows Read: 10000, Total Rows Processed: 10000, Total Chunk Time: 0.245 seconds \n",
      "Rows Read: 10000, Total Rows Processed: 40000, Total Chunk Time: 1.143 secondsRows Read: 10000, Total Rows Processed: 10000, Total Chunk Time: 0.255 seconds \n",
      "Rows Read: 10000, Total Rows Processed: 50000, Total Chunk Time: 1.142 secondsRows Read: 10000, Total Rows Processed: 10000, Total Chunk Time: 0.275 seconds \n",
      "Rows Read: 10000, Total Rows Processed: 60000, Total Chunk Time: 1.284 secondsRows Read: 10000, Total Rows Processed: 10000, Total Chunk Time: 0.217 seconds \n",
      "Rows Read: 10000, Total Rows Processed: 70000, Total Chunk Time: 1.021 seconds \n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------------------\n",
    "# 3. Split the dataset into train and test data.\n",
    "#-----------------------------------------------------------------------\n",
    "# Split the data between train and test sets reproducing LeCun's split.\n",
    "dataSplit <-\n",
    "    rxSplit(dataset,\n",
    "            splitByFactor = \"splitVar\",\n",
    "            outFilesBase = tempfile())\n",
    "\n",
    "# Name the train and test datasets.\n",
    "dataTrain <- dataSplit[[1]]\n",
    "dataTest <- dataSplit[[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above output that there are 60,000 images in the training set, and 10,000 images in the test set. Below, we see the count of each digit in the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows Read: 10000, Total Rows Processed: 10000, Total Chunk Time: 0.005 seconds\n",
      "Rows Read: 10000, Total Rows Processed: 20000, Total Chunk Time: Less than .001 seconds\n",
      "Rows Read: 10000, Total Rows Processed: 30000, Total Chunk Time: Less than .001 seconds\n",
      "Rows Read: 10000, Total Rows Processed: 40000, Total Chunk Time: Less than .001 seconds\n",
      "Rows Read: 10000, Total Rows Processed: 50000, Total Chunk Time: Less than .001 seconds\n",
      "Rows Read: 10000, Total Rows Processed: 60000, Total Chunk Time: 0.001 seconds \n",
      "Computation time: 0.015 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Label</th><td>0   </td><td>1   </td><td>2   </td><td>3   </td><td>4   </td><td>5   </td><td>6   </td><td>7   </td><td>8   </td><td>9   </td></tr>\n",
       "\t<tr><th scope=row>Counts</th><td>5923</td><td>6742</td><td>5958</td><td>6131</td><td>5842</td><td>5421</td><td>5918</td><td>6265</td><td>5851</td><td>5949</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       "\tLabel & 0    & 1    & 2    & 3    & 4    & 5    & 6    & 7    & 8    & 9   \\\\\n",
       "\tCounts & 5923 & 6742 & 5958 & 6131 & 5842 & 5421 & 5918 & 6265 & 5851 & 5949\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "1. '0'\n",
       "2. '5923'\n",
       "3. '1'\n",
       "4. '6742'\n",
       "5. '2'\n",
       "6. '5958'\n",
       "7. '3'\n",
       "8. '6131'\n",
       "9. '4'\n",
       "10. '5842'\n",
       "11. '5'\n",
       "12. '5421'\n",
       "13. '6'\n",
       "14. '5918'\n",
       "15. '7'\n",
       "16. '6265'\n",
       "17. '8'\n",
       "18. '5851'\n",
       "19. '9'\n",
       "20. '5949'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n",
       "Label  0    1    2    3    4    5    6    7    8    9    \n",
       "Counts 5923 6742 5958 6131 5842 5421 5918 6265 5851 5949 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows Read: 10000, Total Rows Processed: 10000, Total Chunk Time: 0.008 seconds \n",
      "Computation time: 0.020 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Label</th><td>0   </td><td>1   </td><td>2   </td><td>3   </td><td>4   </td><td>5   </td><td>6   </td><td>7   </td><td>8   </td><td>9   </td></tr>\n",
       "\t<tr><th scope=row>Counts</th><td> 980</td><td>1135</td><td>1032</td><td>1010</td><td> 982</td><td> 892</td><td> 958</td><td>1028</td><td> 974</td><td>1009</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       "\tLabel & 0    & 1    & 2    & 3    & 4    & 5    & 6    & 7    & 8    & 9   \\\\\n",
       "\tCounts &  980 & 1135 & 1032 & 1010 &  982 &  892 &  958 & 1028 &  974 & 1009\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "1. '0'\n",
       "2. ' 980'\n",
       "3. '1'\n",
       "4. '1135'\n",
       "5. '2'\n",
       "6. '1032'\n",
       "7. '3'\n",
       "8. '1010'\n",
       "9. '4'\n",
       "10. ' 982'\n",
       "11. '5'\n",
       "12. ' 892'\n",
       "13. '6'\n",
       "14. ' 958'\n",
       "15. '7'\n",
       "16. '1028'\n",
       "17. '8'\n",
       "18. ' 974'\n",
       "19. '9'\n",
       "20. '1009'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n",
       "Label  0    1    2    3    4    5    6    7    8    9    \n",
       "Counts  980 1135 1032 1010  982  892  958 1028  974 1009 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t(as.data.frame(rxSummary(~ Label, dataTrain)$categorical))\n",
    "t(as.data.frame(rxSummary(~ Label, dataTest)$categorical))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Model\">2.4. DEFINE THE MODEL</a>\n",
    "\n",
    "The model is a formula that describes what column has the label, and what columns are to be used to rxPredict the label. Since we will use the pixel values of the images as features, we create a formula that says that Label is to be rxPredicted by these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------\n",
    "# 4. Define the model to be fit.\n",
    "#-----------------------------------------------------------------------\n",
    "# The variables in the data\n",
    "allVars <- names(dataTrain)\n",
    "\n",
    "# The image's pixel values.\n",
    "xVars <- setdiff(allVars, c(\"Label\", \"splitVar\"))\n",
    "\n",
    "# The model is a formula that says that an image is to be classified\n",
    "# using its pixel values.\n",
    "model <- formula(paste(\"Label ~\", paste(xVars, collapse = \" + \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The left-hand side of the formula is the label, while the right-hand side lists the rxPredictors.\n",
    "\n",
    "*Note: We do not print this formula because of its size.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Fit\">2.5. FIT THE MODEL</a>\n",
    "\n",
    "The model will be fit by learners that can rxPredict class data: rxLogisticRegression, rxNeuralNet with a simple deep learning architecture, and rxNeuralNet with LeCun's Net5 architecture. In the next section, each fit will be used to score the test data. The comments in this section give a glimpse of the kind of work done by each learner.\n",
    "\n",
    "We begin by fitting a multi-class logistic regression. This approach is not deep learning, and  provides a benchmark for comparison of the performance and learning times of the deep learning approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically adding a MinMax normalization transform, use 'norm=Warn' or 'norm=No' to turn this behavior off.\n",
      "Beginning read for block: 1\n",
      "Rows Read: 10000, Read Time: 0.145, Transform Time: 0\n",
      "Beginning read for block: 2\n",
      "Rows Read: 10000, Read Time: 0.105, Transform Time: 0\n",
      "Beginning read for block: 3\n",
      "Rows Read: 10000, Read Time: 0.096, Transform Time: 0\n",
      "Beginning read for block: 4\n",
      "Rows Read: 10000, Read Time: 0.091, Transform Time: 0\n",
      "Beginning read for block: 5\n",
      "Rows Read: 10000, Read Time: 0.096, Transform Time: 0\n",
      "Beginning read for block: 6\n",
      "Rows Read: 10000, Read Time: 0.093, Transform Time: 0\n",
      "Beginning read for block: 7\n",
      "No rows remaining. Finished reading data set. \n",
      "Beginning read for block: 1\n",
      "Rows Read: 10000, Read Time: 0.128, Transform Time: 0\n",
      "Beginning read for block: 2\n",
      "Rows Read: 10000, Read Time: 0.135, Transform Time: 0\n",
      "Beginning read for block: 3\n",
      "Rows Read: 10000, Read Time: 0.131, Transform Time: 0\n",
      "Beginning read for block: 4\n",
      "Rows Read: 10000, Read Time: 0.105, Transform Time: 0\n",
      "Beginning read for block: 1\n",
      "Rows Read: 10000, Read Time: 0.134, Transform Time: 0\n",
      "Beginning read for block: 2\n",
      "Rows Read: 10000, Read Time: 0.142, Transform Time: 0\n",
      "Beginning read for block: 3\n",
      "Rows Read: 10000, Read Time: 0.127, Transform Time: 0\n",
      "Beginning read for block: 4\n",
      "Rows Read: 10000, Read Time: 0.125, Transform Time: 0\n",
      "Beginning read for block: 5\n",
      "Rows Read: 10000, Read Time: 0.18, Transform Time: 0\n",
      "Beginning read for block: 6\n",
      "Rows Read: 10000, Read Time: 0.16, Transform Time: 0\n",
      "Beginning read for block: 7\n",
      "No rows remaining. Finished reading data set. \n",
      "Wrote 60000 rows across 2 columns in 00:00:02.8713140\n",
      "LBFGS multi-threading will attempt to load dataset into memory. In case of out-of-memory issues, turn off multi-threading by setting trainThreads to 1.\n",
      "Beginning optimization\n",
      "num vars: 7850\n",
      "improvement criterion: Mean Improvement\n",
      "L1 regularization selected 3750 of 7850 weights.\n",
      "Not training a calibrator because it is not needed.\n",
      "Elapsed time: 00:00:39.9960421\n",
      "Elapsed time: 00:00:00.2057257\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------------------\n",
    "# 5. Fit the model using different learners.\n",
    "#-----------------------------------------------------------------------\n",
    "# Fit the model with rxLogisticRegression. This finds the variable weights that\n",
    "# are most useful for classifying images. The rxLogisticRegression learner\n",
    "# automatically adjusts the weights to select those variables that are\n",
    "# most useful for classification. Unlike the convolutional network\n",
    "# approaches shown below, this logistic regression does not take into\n",
    "# account the spatial relationships between the pixels of the images.\n",
    "rxLogisticRegressionFit <- rxLogisticRegression(model, dataTrain, type = \"multiClass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then fit a four-layer convolutional neural network (CNN). This network learns spatial features in two successive sets of convolutional feature map. It then combines the results of the second convolutional layer into 100 features, and these are used by the result layer to classify the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not adding a normalizer.\n",
      "Beginning read for block: 1\n",
      "Rows Read: 10000, Read Time: 0.128, Transform Time: 0\n",
      "Beginning read for block: 2\n",
      "Rows Read: 10000, Read Time: 0.11, Transform Time: 0\n",
      "Beginning read for block: 3\n",
      "Rows Read: 10000, Read Time: 0.111, Transform Time: 0\n",
      "Beginning read for block: 4\n",
      "Rows Read: 10000, Read Time: 0.107, Transform Time: 0\n",
      "Beginning read for block: 1\n",
      "Rows Read: 10000, Read Time: 0.14, Transform Time: 0\n",
      "Beginning read for block: 2\n",
      "Rows Read: 10000, Read Time: 0.106, Transform Time: 0\n",
      "Beginning read for block: 3\n",
      "Rows Read: 10000, Read Time: 0.1, Transform Time: 0\n",
      "Beginning read for block: 4\n",
      "Rows Read: 10000, Read Time: 0.104, Transform Time: 0\n",
      "Beginning read for block: 5\n",
      "Rows Read: 10000, Read Time: 0.154, Transform Time: 0\n",
      "Beginning read for block: 6\n",
      "Rows Read: 10000, Read Time: 0.133, Transform Time: 0\n",
      "Beginning read for block: 7\n",
      "No rows remaining. Finished reading data set. \n",
      "Wrote 60000 rows across 2 columns in 00:00:02.7223789\n",
      "Using: SSE Math\n",
      "Loading net from: \r\n",
      "\r\n",
      "***** Net definition *****\r\n",
      "  const T = true;\r\n",
      "  const F = false;\r\n",
      "  input Picture [28, 28];\r\n",
      "  hidden Convolve1 [5, 12, 12] from Picture convolve {\r\n",
      "    InputShape = [28, 28];\r\n",
      "    KernelShape = [5, 5];\r\n",
      "    Stride = [2, 2];\r\n",
      "    MapCount = 5;\r\n",
      "  }\r\n",
      "  hidden Convolve2 [50, 4, 4] from Convolve1 convolve {\r\n",
      "    InputShape = [5, 12, 12];\r\n",
      "    KernelShape = [1, 5, 5];\r\n",
      "    Stride = [1, 2, 2];\r\n",
      "    Sharing = [F, T, T];\r\n",
      "    MapCount = 10;\r\n",
      "  }\r\n",
      "  hidden Full3 [100] from Convolve2 all;\r\n",
      "  output Result [10] from Full3 all;\r\n",
      "***** Reduced *****\r\n",
      "  const T = true;\r\n",
      "  const F = false;\r\n",
      "  input Picture [28, 28];\r\n",
      "  hidden Convolve1 [5, 12, 12] from Picture convolve {\r\n",
      "    InputShape = [28, 28];\r\n",
      "    KernelShape = [5, 5];\r\n",
      "    Stride = [2, 2];\r\n",
      "    MapCount = 5;\r\n",
      "  }\r\n",
      "  hidden Convolve2 [50, 4, 4] from Convolve1 convolve {\r\n",
      "    InputShape = [5, 12, 12];\r\n",
      "    KernelShape = [1, 5, 5];\r\n",
      "    Stride = [1, 2, 2];\r\n",
      "    Sharing = [false, true, true];\r\n",
      "    MapCount = 10;\r\n",
      "  }\r\n",
      "  hidden Full3 100 from Convolve2 all;\r\n",
      "  output Result 10 from Full3 all;\r\n",
      "***** End net definition *****\r\n",
      "Input count: 784\n",
      "Output count: 10\n",
      "Output Function: SoftMax\n",
      "Loss Function: CrossEntropy\n",
      "PreTrainer: NoPreTrainer\n",
      "___________________________________________________________________\n",
      "Starting training...\n",
      "Learning rate: 0.001000\n",
      "Momentum: 0.000000\n",
      "InitWtsDiameter: 1.000000\n",
      "___________________________________________________________________\n",
      "Initializing 3 Hidden Layers, 82540 Weights...\n",
      "Estimated Pre-training MeanError = 5.269557\n",
      "Iter:1/9, MeanErr=1.535975(-70.85%%), 693.46M WeightUpdates/sec\n",
      "Iter:2/9, MeanErr=0.653371(-57.46%%), 709.24M WeightUpdates/sec\n",
      "Iter:3/9, MeanErr=0.485036(-25.76%%), 722.39M WeightUpdates/sec\n",
      "Iter:4/9, MeanErr=0.405417(-16.42%%), 638.19M WeightUpdates/sec\n",
      "Iter:5/9, MeanErr=0.357963(-11.71%%), 724.03M WeightUpdates/sec\n",
      "Iter:6/9, MeanErr=0.329527(-7.94%%), 720.12M WeightUpdates/sec\n",
      "Iter:7/9, MeanErr=0.299872(-9.00%%), 737.07M WeightUpdates/sec\n",
      "Iter:8/9, MeanErr=0.280437(-6.48%%), 710.89M WeightUpdates/sec\n",
      "Iter:9/9, MeanErr=0.269260(-3.99%%), 691.28M WeightUpdates/sec\n",
      "Done!\n",
      "Estimated Post-training MeanError = 0.265417\n",
      "___________________________________________________________________\n",
      "Not training a calibrator because it is not needed.\n",
      "Elapsed time: 00:01:12.3026364\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------------------\n",
    "# Fit the model with rxNeuralNet. This learns which neural network\n",
    "# weights are needed to classify images as digits based on the pixel\n",
    "# value variables. The 'numIterations' input says how many times the\n",
    "# learners goes over the training data to find the correct weights.\n",
    "#-----------------------------------------------------------------------\n",
    "# TRY THIS: Double numIterations from 9 to 18 and see:\n",
    "# 1. how much better the fit network gets at digit classification, and\n",
    "# 2. how much longer the learner needs to fit the network.\n",
    "#-----------------------------------------------------------------------\n",
    "# The definition of the convolutional neural network.\n",
    "rxNeuralNet <- readChar(file.path(dataDir, \"MNIST.nn\"),\n",
    "                      file.info(file.path(dataDir, \"MNIST.nn\"))$size)\n",
    "rxNeuralNetFit <- rxNeuralNet(model, data = dataTrain,\n",
    "                          type = \"multiClass\",\n",
    "                          numIterations = 9,\n",
    "                          netDefinition = rxNeuralNet,\n",
    "                          initWtsDiameter = 1.0,\n",
    "                          normalize = \"No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the neural network and the logistic regression:How long did each take to fit?\n",
    "\n",
    "Finally, we fit a seven-layer CNN similar to the one described by Yann LeCun in his 1998 paper. In successive layers, this network alternates sets of convolutional feature maps and subsampling.  It then combines the 120 features produced by the last convolutional layer into 84 features, and these are used by the result layer to classify the images. For more information, see http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf.\n",
    "\n",
    "*Note: The cell below can take more than eight minutes to run to completion.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------\n",
    "# Fit the model with rxNeuralNet. This network is an approximation of\n",
    "# LeNet-5, Yann LeCun's 1998 convolutional network.\n",
    "#-----------------------------------------------------------------------\n",
    "# TRY THIS: Increase numIterations until the fit of LeCun-5 reaches 99%\n",
    "# accuracy.\n",
    "#-----------------------------------------------------------------------\n",
    "# The definition of the LeCun-5 neural network.\n",
    "leCun5Net <- readChar(file.path(dataDir, \"LeCun5.nn\"),\n",
    "                      file.info(file.path(dataDir, \"LeCun5.nn\"))$size)\n",
    "if (file.exists(file = file.path(dataDir, \"leCun5NetFit.RData\"))) {\n",
    "    load(file = file.path(dataDir, \"leCun5NetFit.RData\"))\n",
    "} else {\n",
    "    leCun5NetFit <- rxNeuralNet(model, data = dataTrain,\n",
    "                              type = \"multiClass\",\n",
    "                              numIterations = 9,\n",
    "                              netDefinition = leCun5Net,\n",
    "                              initWtsDiameter = 1.0,\n",
    "                              normalize = \"No\")\n",
    "    save(leCun5NetFit, file = file.path(dataDir, \"leCun5NetFit.RData\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare LeCun's neural network and the previous one: How long did each take to fit?\n",
    "\n",
    "In the next two sections, we will compute the classification performance of each method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Score\">2.6. SCORE THE TEST DATA</a>\n",
    "\n",
    "Each fit will be used to score the test data, and then the score columns are concatenated in one table. This provides each fit's rxPredictions for side-by-side convenient comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning read for block: 1\n",
      "Rows Read: 10000, Read Time: 0.138, Transform Time: 0\n",
      "Beginning read for block: 2\n",
      "No rows remaining. Finished reading data set. \n",
      "Elapsed time: 00:00:00.7597420\n",
      "Finished writing 10000 rows.\n",
      "Writing completed.\n",
      "Beginning read for block: 1\n",
      "Rows Read: 10000, Read Time: 0.13, Transform Time: 0\n",
      "Beginning read for block: 2\n",
      "No rows remaining. Finished reading data set. \n",
      "Elapsed time: 00:00:00.9389510\n",
      "Finished writing 10000 rows.\n",
      "Writing completed.\n",
      "Beginning read for block: 1\n",
      "Rows Read: 10000, Read Time: 0.124, Transform Time: 0\n",
      "Beginning read for block: 2\n",
      "No rows remaining. Finished reading data set. \n",
      "Elapsed time: 00:00:02.9220124\n",
      "Finished writing 10000 rows.\n",
      "Writing completed.\n",
      "File merge progress at row: 10000\n",
      "Time to merge data file: 0.109 seconds\n",
      "Rows Read: 10000, Total Rows Processed: 10000, Total Chunk Time: 0.040 seconds \n",
      "File merge progress at row: 10000\n",
      "Time to merge data file: 0.156 seconds\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------------------\n",
    "# 6. Score the held-aside test data with the fit models.\n",
    "#-----------------------------------------------------------------------\n",
    "# The scores are each record's probability of being one of the ten\n",
    "# digits. The rxPredicted label correspond to the digit with the highest\n",
    "# score. We combine each learner's rxPredictions and the label into one\n",
    "# Xdf.\n",
    "rxLogisticRegressionScores <-\n",
    "    rxPredict(rxLogisticRegressionFit, dataTest, suffix = \".rxLogisticRegression\",\n",
    "            extraVarsToWrite = \"Label\",\n",
    "            outData = tempfile(fileext = \".xdf\"))\n",
    "rxNeuralNetScores <-\n",
    "    rxPredict(rxNeuralNetFit, dataTest, suffix = \".rxNeuralNet\",\n",
    "            outData = tempfile(fileext = \".xdf\"))\n",
    "leCun5NetScores <-\n",
    "    rxPredict(leCun5NetFit, dataTest, suffix = \".leCun5Net\",\n",
    "            outData = tempfile(fileext = \".xdf\"))\n",
    "fitScores <- rxMerge(list(rxLogisticRegressionScores, rxNeuralNetScores, leCun5NetScores),\n",
    "                     type = \"oneToOne\")\n",
    "names(fitScores) <- gsub(\"PredictedLabel.\", \"\", names(fitScores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see in the above results that the number of rows in the results is the same as the number of rows in the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Compare\">2.7. COMPARE THE FIT MODEL PERFORMANCE</a>\n",
    "\n",
    "For each fit model, its rxPredictions and the Label are used to compute a confusion table for that fit. A confusion table shows the numbers of each actual digit that was classified as one of the digits 0 through 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows Read: 10000, Total Rows Processed: 10000, Total Chunk Time: Less than .001 seconds \n",
      "Computation time: 0.004 seconds.\n",
      "Rows Read: 10000, Total Rows Processed: 10000, Total Chunk Time: 0.001 seconds \n",
      "Computation time: 0.004 seconds.\n",
      "Rows Read: 10000, Total Rows Processed: 10000, Total Chunk Time: 0.001 seconds \n",
      "Computation time: 0.004 seconds.\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------------------\n",
    "# 7. Compare the performance of fit models.\n",
    "#-----------------------------------------------------------------------\n",
    "# Create square confusion tables. The entries of these tables count the\n",
    "# number of images of a digit that were classified as being one of the\n",
    "# ten digits. The entries on a table's main diagonal, stretching from\n",
    "# the top-left corner to the bottom-right corner, count the number of\n",
    "# images that were correctly classified. The row sums are the counts\n",
    "# of the number of times each digit was in an image. The column sums\n",
    "# are the counts of the number of times each digit was rxPredicted.\n",
    "rxLogisticRegressionConfusion <-\n",
    "    rxCrossTabs(~ Label:rxLogisticRegression, fitScores, returnXtabs = TRUE)\n",
    "rxNeuralNetConfusion <-\n",
    "    rxCrossTabs(~ Label:rxNeuralNet, fitScores, returnXtabs = TRUE)\n",
    "leCun5NetConfusion <-\n",
    "    rxCrossTabs(~ Label:leCun5Net, fitScores, returnXtabs = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the confusion table for the rxLogisticRegression learner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     rxLogisticRegression\n",
       "Label    0    1    2    3    4    5    6    7    8    9\n",
       "    0  958    0    2    3    0    7    4    5    1    0\n",
       "    1    0 1112    3    2    0    2    3    2   11    0\n",
       "    2    6    8  931   14   10    3   13   10   34    3\n",
       "    3    4    1   16  922    0   25    3   11   22    6\n",
       "    4    1    1    5    3  920    0    9    3    8   32\n",
       "    5   10    2    3   35    9  777   14    8   31    3\n",
       "    6    9    3    5    2    8   15  912    2    2    0\n",
       "    7    1    9   23    5    6    1    0  950    1   32\n",
       "    8    7   10    5   21    9   26   10    8  867   11\n",
       "    9   11    8    1    9   26    6    0   19    7  922"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rxLogisticRegressionConfusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of the table counts the images that show the row's digit, and each column has the images that were classified as the column's digit. The numbers on the diagonal show the counts of times the model fit with rxLogisticRegression correctly assigned a digit to an image. The off-diagonal numbers show the errors.\n",
    "\n",
    "The single fitScores table also allows comparison of the rxPredictions of each learner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows Read: 10000, Total Rows Processed: 10000, Total Chunk Time: 0.001 seconds \n",
      "Computation time: 0.003 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                    rxNeuralNet\n",
       "rxLogisticRegression    0    1    2    3    4    5    6    7    8    9\n",
       "                   0  969    0    6    5    0   12    9    0    3    3\n",
       "                   1    0 1117   11    0    1    2    1   10   11    1\n",
       "                   2    2    1  938   14    3    3   11   15    6    1\n",
       "                   3    3    0   14  947    2   27    3    6   12    2\n",
       "                   4    0    3    5    1  918   10    8    8    3   32\n",
       "                   5    8    1    3   35    1  780   11    2   18    3\n",
       "                   6    3    1   11    2    5   18  921    0    7    0\n",
       "                   7    4    4    8   10    2    6    2  963    6   13\n",
       "                   8    1    6   31   23    7   30    1    2  880    3\n",
       "                   9    2    1    5    4   35    7    0   33    7  915"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rxCrossTabs(~ rxLogisticRegression:rxNeuralNet, fitScores, returnXtabs = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers on the diagonal show that the model fit with rxLogisticRegression and with convolutional rxNeuralNet agree on most of their rxPredictions. The off-diagonal numbers show the areas of disagreement.\n",
    "\n",
    "Below, the confusion tables are then used to compute the per-digit accuracy, precision, and recall for each fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The accuracy of the fit models. This is the ratio of the number of\n",
    "# correct classification of images as having a digit to the total\n",
    "# number of images that were classified.\n",
    "accuracy <-\n",
    "    cbind(rxLogisticRegression = sum(diag(rxLogisticRegressionConfusion)) /\n",
    "                             sum(rxLogisticRegressionConfusion),\n",
    "          rxNeuralNet = sum(diag(rxNeuralNetConfusion)) /\n",
    "                             sum(rxNeuralNetConfusion),\n",
    "          leCun5Net = sum(diag(leCun5NetConfusion)) /\n",
    "                             sum(leCun5NetConfusion))\n",
    "rownames(accuracy) <- \"Accuracy\"\n",
    "names(dimnames(accuracy)) <- c(\"\", \"Learner\")\n",
    "\n",
    "# The precision and recall of the fit model, by digit. For a given\n",
    "# digit, the precision is the fraction of assignments of that digit to\n",
    "# images that were correct. In contrast, the recall is the fraction of\n",
    "# images of that digit that were correct assigned that digit.\n",
    "precision <-\n",
    "    rbind(rxLogisticRegression = diag(rxLogisticRegressionConfusion) /\n",
    "                             colSums(rxLogisticRegressionConfusion),\n",
    "          rxNeuralNet = diag(rxNeuralNetConfusion) /\n",
    "                             colSums(rxNeuralNetConfusion),\n",
    "          leCun5Net = diag(leCun5NetConfusion) /\n",
    "                             colSums(leCun5NetConfusion))\n",
    "names(dimnames(precision)) <- c(\"Learner\", \"Digit\")\n",
    "\n",
    "recall <-\n",
    "    rbind(rxLogisticRegression = diag(rxLogisticRegressionConfusion) /\n",
    "                             rowSums(rxLogisticRegressionConfusion),\n",
    "          rxNeuralNet = diag(rxNeuralNetConfusion) /\n",
    "                             rowSums(rxNeuralNetConfusion),\n",
    "          leCun5Net = diag(leCun5NetConfusion) /\n",
    "                            rowSums(leCun5NetConfusion))\n",
    "names(dimnames(recall)) <- c(\"Learner\", \"Digit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These accuracy, precision, and recall data are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Learner\n",
      "           rxLogisticRegression rxNeuralNet leCun5Net\n",
      "  Accuracy                 0.93        0.96      0.98\n",
      "\n",
      "Per digit precision:\n",
      "                      Digit\n",
      "Learner                   0    1    2    3    4    5    6    7    8    9\n",
      "  rxLogisticRegression 0.95 0.96 0.94 0.91 0.93 0.90 0.94 0.93 0.88 0.91\n",
      "  rxNeuralNet          0.97 0.98 0.95 0.93 0.97 0.94 0.96 0.95 0.95 0.96\n",
      "  leCun5Net            0.98 0.99 0.97 0.96 0.98 0.99 0.98 0.97 0.97 0.98\n",
      "\n",
      "Per digit recall:\n",
      "                      Digit\n",
      "Learner                   0    1    2    3    4    5    6    7    8    9\n",
      "  rxLogisticRegression 0.98 0.98 0.90 0.91 0.94 0.87 0.95 0.92 0.89 0.91\n",
      "  rxNeuralNet          0.98 0.98 0.95 0.96 0.97 0.95 0.97 0.96 0.93 0.93\n",
      "  leCun5Net            0.99 0.99 0.98 0.98 0.98 0.97 0.98 0.97 0.96 0.96\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------------------\n",
    "# Report the results.\n",
    "#-----------------------------------------------------------------------\n",
    "# Print the fit models's accuracies, and their per digit precision and\n",
    "# recall.\n",
    "print(accuracy, digits = 2)\n",
    "cat(\"\\nPer digit precision:\\n\")\n",
    "print(precision, digits = 2)\n",
    "cat(\"\\nPer digit recall:\\n\")\n",
    "print(recall, digits = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, barplots are created to show side-by-side the per-digit precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAABNTU1oaGh8fHyM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\nHIEufd3Z/DkAAAAASUVORK5CYII=",
      "text/plain": [
       "Plot with title \"Per Digit Precision\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAABNTU1oaGh8fHyM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\nCBkIkBAyECAhZCBAQshAgISQgf4PDaZC5/3SVBEAAAAASUVORK5CYII=",
      "text/plain": [
       "Plot with title \"Per Digit Recall\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Barplots showing side-by-side the per digit precision and recall\n",
    "# achieved by the fit models on the test data.\n",
    "barplot(precision,\n",
    "        legend.text = TRUE, beside = TRUE,\n",
    "        main = \"Per Digit Precision\",\n",
    "        xlab = \"Digit\", ylab = \"Precision\", ylim = 0:1,\n",
    "        args.legend = list(x = \"bottomright\"))\n",
    "barplot(recall,\n",
    "        legend.text = TRUE, beside = TRUE,\n",
    "        main = \"Per Digit Recall\",\n",
    "        xlab = \"Digit\", ylab = \"Recall\", ylim = 0:1,\n",
    "        args.legend = list(x = \"bottomright\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"Next\">3. WHAT'S NEXT?</a>\n",
    "\n",
    "In the Microsoft ML samples directory, the script MNIST.R contains all the R code used in this tutorial. It also contains other scripts formatted to follow the steps used for this tutorial. Try them out interactively, and learn about other Microsoft ML capabilities."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
